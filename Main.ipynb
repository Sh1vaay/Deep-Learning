{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT  LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2EPC5RCQQ9S"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\"Leaves\",shuffle =True,image_size = (255, 255), batch_size = 32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING CLASSES PRESENT IN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PGGb_doYggF",
    "outputId": "4e8447d9-c824-4f7b-c872-772c0216342f"
   },
   "outputs": [],
   "source": [
    "dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT OF IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar=\"/home/admin1/Downloads/Leaves/\"\n",
    "class_names = sorted(os.listdir(dar))\n",
    "class_dis = [len(os.listdir(dar + name)) for name in class_names]\n",
    "fig = px.pie(names=class_names, values=class_dis, hole=0.3)\n",
    "fig.update_layout({\"title\":{\"text\":\"No of Images in Each Disease\", \"x\":0.50}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING THE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for image_batch, label_batch in dataset.take(1):\n",
    "  for i in range(30):\n",
    "    ax = plt.subplot(6,5,i+1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[label_batch[i]]);\n",
    "    plt.axis(\"OFF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINING DATA FOR TRAINING, TESTING AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOp3DYEeCcJA"
   },
   "outputs": [],
   "source": [
    "def dataset_partition(ds,train_split=0.8,val_split=0.1,test_split=0.1,shuffle=True,shuffle_size=10000):\n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size,seed=8)\n",
    "\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    \n",
    "    val_ds = ds.skip(train_size).take(val_size) \n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds,val_ds,test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset_partition(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batches of Training data :- \",len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batches of Validation data :- \",len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batches of Testing data :- \",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING :- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzLfNAiyFvzk"
   },
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(255, 255),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrYviBZhbQg1"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCTaf4l6bYof"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    resize_and_rescale,data_augmentation,\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=(32, 255, 255, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    #multiclass classification\n",
    "    layers.Dense(5, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(32, 255, 255, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsx0lRDKbfxu",
    "outputId": "bbed0151-4f6a-472c-8dfe-9d41b14b2f11"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATCHZA5Pcf-n"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',patience=10,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q90jF95Kcscp",
    "outputId": "6600cb51-fd30-4f7c-fd31-6337ef350818"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data, epochs=10,callbacks=early_stopping, validation_data=valid_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbJwaFCQcxAd",
    "outputId": "edfe7d6d-10ec-4ded-dd3b-77b1b1ecd038"
   },
   "outputs": [],
   "source": [
    "los,acc = model.evaluate(valid_data);\n",
    "print(\"Loss is :-\",los)\n",
    "print(\"Accuracy is :-\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title(\"ACCURACY\",color=\"red\")\n",
    "plt.ylabel(\"ACCURACY\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.legend(['accuracy','val_accuracy'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss of the model\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"LOSS\",color=\"red\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.legend(['loss','val_loss'],loc='upper left')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    predictions = model.predict (img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tru=[]\n",
    "y_predicted=[]\n",
    "for i in range(len(test_data)):\n",
    "    for images,labels in test_data.take(1):\n",
    "        for i in range(32):\n",
    "            predicted_class= predict(images[i].numpy())\n",
    "            actual_class = class_names[labels[i]]\n",
    "            y_tru.append(actual_class)\n",
    "            y_predicted.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of first 10 labels in testing data\n",
    "y_pre=model.predict(test_data)\n",
    "y_predict=[np.argmax(i) for i in y_pre]\n",
    "ls=[]\n",
    "for i in y_predict[:10]:\n",
    "    if i==0:\n",
    "        ls.append(\"Black Spot\")\n",
    "    elif i==1:\n",
    "        ls.append(\"Canker\")\n",
    "    elif i==2:\n",
    "        ls.append(\"Greening\")\n",
    "    elif i==3:\n",
    "        ls.append(\"Healthy\")\n",
    "    else:\n",
    "        ls.append(\"Mealnose\")\n",
    "print(\"Predicted Classes :-\\n\",ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c=confusion_matrix(y_tru,y_predicted,labels=dataset.class_names)\n",
    "display_c_m = ConfusionMatrixDisplay(c, display_labels=dataset.class_names)\n",
    "# Setting colour map to be used\n",
    "display_c_m.plot(cmap='OrRd', xticks_rotation=25)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title('Confusion Matrix', fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c=confusion_matrix(y_tru,y_predicted,labels=dataset.class_names)\n",
    "print(\"Confusion Matrix :-\\n\",c)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_tru,y_predicted,labels=dataset.class_names,target_names=dataset.class_names)\n",
    "print(\"Classification Report:-\\n\",report);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_image, batch_label in train_data.take(1):\n",
    "    first_image = batch_image[0].numpy().astype('uint8')\n",
    "    first_label = dataset.class_names[batch_label[0]]\n",
    "    \n",
    "    print('First image of batch to predict :')\n",
    "    plt.imshow(first_image)\n",
    "    print('Actual label : ', first_label)\n",
    "    \n",
    "    batch_prediction = model.predict(batch_image)\n",
    "    prediction = dataset.class_names[np.argmax(batch_prediction[0])]\n",
    "    print('Predicted label : ', prediction)\n",
    "    plt.axis('off');\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(255, 255, 3),\n",
    "    classes=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoppings = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',patience=10,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING :- VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "history_model = model.fit_generator(\n",
    "  train_data,\n",
    "  validation_data=valid_data,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(train_data),\n",
    "  validation_steps=len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los,acc = model.evaluate(valid_data);\n",
    "print(\"Loss is :-\",los)\n",
    "print(\"Accuracy is :-\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt ### visualisation\n",
    "plt.plot(history_model.history['val_accuracy'])\n",
    "plt.title(\"ACCURACY\",color=\"red\")\n",
    "plt.plot(history_model.history['accuracy'])\n",
    "plt.legend(['val_accuracy',['accuracy']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt ### visualisation\n",
    "plt.plot(history_model.history['val_loss'])\n",
    "plt.title(\"LOSS\",color=\"red\")\n",
    "plt.plot(history_model.history['loss'])\n",
    "plt.legend(['val_loss','loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(test_data)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI TKINTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = tk.Tk()\n",
    "form.geometry(\"1000x500\")\n",
    "form.title('Citrus Plant Disease Classification and Recommendation System Using Deep Learning')\n",
    "form.resizable(False, False)\n",
    "my_font1 = ('times', 18, 'bold',)\n",
    "my_font2 = ('times', 15, 'bold')\n",
    "l1 = tk.Label(form, text='Citrus Plant Disease Classification and Recommendation System Using Deep Learning', \n",
    "              width=70, font=my_font1, bg='white', fg='green', padx = 10, pady = 5)\n",
    "l1.grid(row=1, column=1)\n",
    "b1 = tk.Button(form, text='Upload Leaf Image',\n",
    "               width=20, command=lambda: upload_file())\n",
    "b1.grid(row=3, column=1)\n",
    "l2 = tk.Label(form)\n",
    "l2.grid(row=5, column=1)\n",
    "l3 = tk.Label(form)\n",
    "l3.grid(row=11, column=1)\n",
    "\n",
    "def upload_file():\n",
    "    global img\n",
    "    f_types = [('Image Files', '*.png;*.jpg;*.jpeg')]\n",
    "    filename = filedialog.askopenfilename(filetypes=f_types)\n",
    "    img = Image.open(filename)\n",
    "    img.save(\"leaf.png\")\n",
    "    img_resized = img.resize((255, 255))\n",
    "    img = ImageTk.PhotoImage(img_resized)\n",
    "    l2.config(image=img)\n",
    "    l2.image = img\n",
    "    b3 = tk.Button(form, text='Predict',\n",
    "                   width=20, command=lambda: prediction())\n",
    "    b3.grid(row=9, column=1)\n",
    "\n",
    "def prediction():\n",
    "    model =  models.load_model(\"my_model.h5\")\n",
    "    class_names = ['Black spot', 'Melanose', 'canker', 'greening', 'healthy']\n",
    "    img = cv2.imread(\"leaf.png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (255, 255))\n",
    "    img = (np.expand_dims(img,0))\n",
    "    weights = model.predict(img)\n",
    "    img_prediction = weights.argmax(axis=1)[0]\n",
    "    prediction = class_names[img_prediction]\n",
    "    l3.config(text=f\"Prediction: {prediction}\", font=my_font2, fg=\"green\")    \n",
    "    l4 = tk.Text(form, wrap=WORD, width=90, height=5, fg=\"green\")\n",
    "    l4.delete('1.0', END)    \n",
    "    if prediction != \"healthy\":\n",
    "            treatments = read_csv(\"treatments.csv\")       \n",
    "            treatment = (treatments.loc[treatments['disease'] == prediction]).values.tolist() \n",
    "            l3.config(fg=\"red\")    \n",
    "            l4.insert(INSERT, f\"Recommendation(Treatment) : {treatment[0][1]}\") \n",
    "            l4.config(fg=\"red\")\n",
    "    else:\n",
    "          l4.insert(INSERT, f\"\\t\\tNo Disease Detected.\")     \n",
    "    l4.config(state=DISABLED, highlightthickness = 0, borderwidth=0, bg='#f0f0f0')\n",
    "    l4.grid(row=20, column=1)\n",
    "           \n",
    "form.mainloop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
